{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code derived from TensorFlow Tutorials/Hvass\n",
    "<br>Modified by TF to include Tensorboard logging\n",
    "<br>Modified by TF to remove reLU\n",
    "<br>Modified by TF to include dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Configuration of Neural Network </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convolution Layer 1\n",
    "filter_size1 = 5 #Convolution filters are 5x5 pixels\n",
    "num_filters1 = 16 #There are 16 of these filters\n",
    "\n",
    "#Convolution Layer 2\n",
    "filter_size2 = 5 #As above, 5x5 pixels\n",
    "num_filters2 = 36 #there are 36 filters\n",
    "\n",
    "#Fully-connected layer\n",
    "fc_size = 128 #number of neurons in the fully connected layer\n",
    "\n",
    "#tensorboard log directory\n",
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "--Training set:\t\t55000\n",
      "--Test-set:\t\t10000\n",
      "--Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"--Training set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"--Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"--Validation-set:\\t{}\".format(len(data.validation.labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.test.cls = np.argmax(data.test.labels, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MNIST images are 28x28\n",
    "img_size = 28\n",
    "\n",
    "#Images are stored in flat arrays of this length\n",
    "img_size_flat = img_size*img_size\n",
    "\n",
    "#Tuple with height and width of images used to reshape arrays\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "#Number of color channels for the images\n",
    "num_channels = 1\n",
    "\n",
    "#Number of classes, one for each of 10 digits\n",
    "num_classes = 10\n",
    "\n",
    "#tensorboard log directory\n",
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    #Create figure with 3x3 subplots\n",
    "    fig, axes = plt.subplots(3,3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        #plot image. COME BACK TO THIS CODE TIM\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "        \n",
    "        #show true and predicted classes \n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "        \n",
    "        #show the classes as the label on the x-axis\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        #Remove ticks from the plot\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    #ensure the plot is shown correctly with multiple plots in single cell\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get images\n",
    "images = data.test.images[0:9]\n",
    "\n",
    "#Get the true classes\n",
    "cls_true = data.test.cls[0:9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Function: Creating variables and initializing with random values</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Variable Summaries for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "        \n",
    "        #attach a  lot of summaries to a tensor for visualization. From\n",
    "        #https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "        with tf.name_scope('summaries'):\n",
    "            mean = tf.reduce_mean(var)\n",
    "            tf.summary.scalar('mean', mean)\n",
    "            \n",
    "            with tf.name_scope('stddev'):\n",
    "                stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "            \n",
    "            tf.summary.scalar('stddev', stddev)\n",
    "            tf.summary.scalar('max', tf.reduce_max(var))    \n",
    "            tf.summary.scalar('min', tf.reduce_min(var))\n",
    "            #tf.summary.historgram('histogram', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: to create first convolution layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(input, #previous layer \n",
    "                   num_input_channels,#Num. channels in prev. layer\n",
    "                   filter_size,#width and size of each filter\n",
    "                   num_filters, \n",
    "                   use_pooling=True,): #use 2x2 max pooling\n",
    "    # adding a name scope to ensure logical grouping of layers in graph\n",
    "    with tf.name_scope('Convolutional_Layer'):\n",
    "        \n",
    "        #shape of filter-weights for convolution. Format determined by TensorFlow API\n",
    "        shape = [filter_size,filter_size,num_input_channels,num_filters]\n",
    "    \n",
    "        #Holds the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            #new weights aka filters with the given shape\n",
    "            weights = new_weights(shape=shape)\n",
    "            variable_summaries(weights)\n",
    "        \n",
    "        with tf.name_scope('biases'):\n",
    "            #create new biases one for each filter\n",
    "            biases = new_biases(length=num_filters)\n",
    "            variable_summaries(biases)\n",
    "    \n",
    "        #TensorFlow operation for convolution. Strides are set to 1 in all dimensions. CHECK STRIDE NOTATION\n",
    "        #The first and last stride must be set to 1, \n",
    "        #because the first is for the image number\n",
    "        #second is for the input channel\n",
    "        #e.g. [1,2,2,1] would mean that the filter moves 2 pixels across x and y axes of image\n",
    "        #Padding is set to 'SAME' which means input image is padded with zeros\n",
    "        #making the size of the output the same\n",
    "        layer = tf.nn.conv2d(input=input, \n",
    "                         filter=weights, \n",
    "                        strides=[1,1,1,1],\n",
    "                        padding='SAME')\n",
    "\n",
    "        #biases\n",
    "        layer += biases\n",
    "        \n",
    "        #max pool\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                            ksize=[1,2,2,1],\n",
    "                            strides=[1,2,2,1],\n",
    "                            padding='SAME')\n",
    "    \n",
    "        #Rectified Linear Unit\n",
    "        #Calculates max(x, 0) for each input pixel, x. Adds non-linearity\n",
    "        #Normally ReLU executed before pooling, but since relu(max_pool(x)) == max_pool(relu(x)) \n",
    "        # we save 75% of ReLU operations by max-pooling first.\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "        #dropout\n",
    "        #layer = tf.nn.dropout(layer, 0.3)\n",
    "    \n",
    "        #We use return becauase we will plot the weights later. \n",
    "        return layer, weights\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Flatten a Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    with tf.name_scope('Flatten_Layer'):\n",
    "        #Shape of input layer, assumed to be \n",
    "        #layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "        layer_shape=layer.get_shape()\n",
    "    \n",
    "        #The number of features is: img_height*img_width*num_channels]\n",
    "        num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "        #Reshape layer to just [num_images, num_features]\n",
    "        layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "        return layer_flat, num_features\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Function to create Fully-Connected Layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.1)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Placeholder Variables</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tensor for images, multidimensional matrix, None means the tensor holds arbitrary number of images\n",
    "#with each vector of length img_size_flat representing one image.\n",
    "#x = tf.placeholder(tf.float32,shape=[None,img_size_flat],name='x')\n",
    "\n",
    "with tf.name_scope('Input_Images'):\n",
    "    x = tf.placeholder(tf.float32,shape=[None,img_size_flat],name='x')\n",
    "    \n",
    "    x_image = tf.reshape(x,[-1,img_size,img_size,num_channels])\n",
    "\n",
    "    y_true = tf.placeholder(tf.float32,shape=[None,10],name='y_true')\n",
    "\n",
    "    y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convolutional Layer 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Convolutional_Layer/Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convolutional Layer 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 =\\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                  num_input_channels=num_filters1,\n",
    "                  filter_size=filter_size2,\n",
    "                  num_filters=num_filters2,\n",
    "                  use_pooling=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Convolutional_Layer_1/Relu:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.variables.Variable at 0x11cbf8cf8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weights_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Flatten Layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Flatten_Layer/Reshape:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fully Connected Layer 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Fully Connected Layer 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1, \n",
    "                           num_inputs=fc_size,\n",
    "                        num_outputs=num_classes,\n",
    "                        use_relu=False,\n",
    "                        use_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Fully_Connected_Layer_1/add:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Predicted Class</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"softmax\"):\n",
    "    #note that here we have only used one fc layer as a predictor\n",
    "    y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"y_pred\"):\n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Cross-function to be optimized</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cost'):\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Optimization Method</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Performance Measures</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Accuracy'):\n",
    "    #vector of booleans whether the predicted class equals the true class of the image\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    #type-cast the booleans to floats (False is 0 and True is 1), then take an average\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create cost and accuracy summaries Merge Tensorboard Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar(\"cost\", cost)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "summary_op = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Run Dropout is 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.1\"\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to perform optimization iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    cls_true = data.test.cls\n",
    "    \n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                         y_pred=cls_pred)\n",
    "    #print as text\n",
    "    print(cm)\n",
    "    \n",
    "    #plot as image\n",
    "    plt.matshow(cm)\n",
    "    \n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('true')\n",
    "    \n",
    "    #ensure it is plotted in one Notebook cell\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to show performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy(show_example_errors = False, \n",
    "                       show_confusion_matrix = False):\n",
    "    num_test = len(data.test.images)\n",
    "    \n",
    "    #Array for the predicted class, calculated in batches and filled into this array\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "    \n",
    "    i = 0 \n",
    "    \n",
    "    while i < num_test:\n",
    "        #The ending index for next batch is denoted by j\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        \n",
    "        images = data.test.images[i:j, :]\n",
    "        \n",
    "        labels = data.test.labels[i:j, :]\n",
    "        \n",
    "        feed_dict = {x:images, \n",
    "                    y_true: labels}\n",
    "        \n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        \n",
    "        i = j\n",
    "    \n",
    "    #true class numbers of the test set \n",
    "    cls_true = data.test.cls\n",
    "    \n",
    "    #Boolean array indicating correct/incorrect image classification\n",
    "    correct = (cls_true == cls_pred)\n",
    "    \n",
    "    #Total number of correct images\n",
    "    correct_sum = correct.sum()\n",
    "    \n",
    "    #accuracy is number of correct images over total images in test set\n",
    "    acc = float(correct_sum) / num_test\n",
    "    \n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} /{2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "    \n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 10.3% (1031 /10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   9.4%\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10,000 optimizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    101, Training Accuracy:  39.1%\n",
      "Time usage: 0:00:21\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 35.2% (3524 /10000)\n",
      "Confusion Matrix:\n",
      "[[561  64  40  73  56  32  74  37  24  19]\n",
      " [ 20 631  74  79  49  13  95  73  39  62]\n",
      " [112 204 334  74  38   6 162  27  69   6]\n",
      " [108 167 119 317  55  78  19  75  50  22]\n",
      " [ 39 122  25  46 304  36 158 149  21  82]\n",
      " [210 119  52 108  78  97  43  75  67  43]\n",
      " [105 153  37  18  72  19 505  11  30   8]\n",
      " [ 55 127  40  68 125  25  14 470  17  87]\n",
      " [113 158  78  92  82  69  52 127 159  44]\n",
      " [ 58 110  17  62 215  34  39 273  55 146]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD0CAYAAABuOhhTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFgkjhJAsEkYIIdn/B9ODbOdF2V3nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123639f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_test_accuracy(show_confusion_matrix = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dropout equal to 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.2)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convolutional Layer 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Convolutional_Layer_2/Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convolutional Layer 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 =\\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                  num_input_channels=num_filters1,\n",
    "                  filter_size=filter_size2,\n",
    "                  num_filters=num_filters2,\n",
    "                  use_pooling=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Convolutional_Layer_3/Relu:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.variables.Variable at 0x1239b0f60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weights_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Flatten Layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Flatten_Layer_1/Reshape:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fully Connected Layer 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Fully Connected Layer 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1, \n",
    "                           num_inputs=fc_size,\n",
    "                        num_outputs=num_classes,\n",
    "                        use_relu=False,\n",
    "                        use_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Fully_Connected_Layer_3/add:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.2\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 9.9% (993 /10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  18.8%\n",
      "Time usage: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 10.3% (1035 /10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    101, Training Accuracy:  32.8%\n",
      "Time usage: 0:00:19\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 38.5% (3845 /10000)\n",
      "Confusion Matrix:\n",
      "[[618  82  38  41  14  48  58  31  30  20]\n",
      " [ 36 734  36  78  12  22  37  74  61  45]\n",
      " [115 115 292 189   9  45 101  58  87  21]\n",
      " [ 64  98  66 509  10  44  52  81  61  25]\n",
      " [ 55 118  27  42 232  28  63 113  32 272]\n",
      " [125 122  35 213  17 119  60  67  80  54]\n",
      " [156 113  97  86  21  63 342  17  41  22]\n",
      " [ 53 126  37 121  35  14  15 477  46 104]\n",
      " [102 159  59 192  28  68  56  62 188  60]\n",
      " [ 44 152  29  67 146  20  26 160  31 334]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD0CAYAAABuOhhTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWySMEEJukTBCCLlFwggh5BYJI4SQ2/8HIcAt1YXI6mMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124380e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Equal to 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.3)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.3\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout equal to 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.4)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.4\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Probability = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.2)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.5\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeepProbability = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.2)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.6\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeepProbability = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.2)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.7\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeepProbability = 0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.2)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.8\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeepProbability = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.2)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb0.9\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeepProbability 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.2)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb1.0\"\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        _, c, summary  =session.run([optimizer,cost,summary_op],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
