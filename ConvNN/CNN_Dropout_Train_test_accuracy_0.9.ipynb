{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code derived from TensorFlow Tutorials/Hvass\n",
    "<br>Modified by TF to include Tensorboard logging\n",
    "<br>Modified by TF to remove reLU\n",
    "<br>Modified by TF to include dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Configuration of Neural Network </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convolution Layer 1\n",
    "filter_size1 = 5 #Convolution filters are 5x5 pixels\n",
    "num_filters1 = 16 #There are 16 of these filters\n",
    "\n",
    "#Convolution Layer 2\n",
    "filter_size2 = 5 #As above, 5x5 pixels\n",
    "num_filters2 = 36 #there are 36 filters\n",
    "\n",
    "#Fully-connected layer\n",
    "fc_size = 128 #number of neurons in the fully connected layer\n",
    "\n",
    "#tensorboard log directory\n",
    "#logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs/KeepProb1.0\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "--Training set:\t\t55000\n",
      "--Test-set:\t\t10000\n",
      "--Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"--Training set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"--Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"--Validation-set:\\t{}\".format(len(data.validation.labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.test.cls = np.argmax(data.test.labels, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MNIST images are 28x28\n",
    "img_size = 28\n",
    "\n",
    "#Images are stored in flat arrays of this length\n",
    "img_size_flat = img_size*img_size\n",
    "\n",
    "#Tuple with height and width of images used to reshape arrays\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "#Number of color channels for the images\n",
    "num_channels = 1\n",
    "\n",
    "#Number of classes, one for each of 10 digits\n",
    "num_classes = 10\n",
    "\n",
    "#tensorboard log directory\n",
    "#logs_path = \"/Users/Tim/Documents/BacktoSchool/Zicklin/Handwriting/logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    #Create figure with 3x3 subplots\n",
    "    fig, axes = plt.subplots(3,3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        #plot image. COME BACK TO THIS CODE TIM\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "        \n",
    "        #show true and predicted classes \n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "        \n",
    "        #show the classes as the label on the x-axis\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        #Remove ticks from the plot\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    #ensure the plot is shown correctly with multiple plots in single cell\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get images\n",
    "images = data.test.images[0:9]\n",
    "\n",
    "#Get the true classes\n",
    "cls_true = data.test.cls[0:9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Function: Creating variables and initializing with random values</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Variable Summaries for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "        \n",
    "        #attach a  lot of summaries to a tensor for visualization. From\n",
    "        #https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "        with tf.name_scope('summaries'):\n",
    "            mean = tf.reduce_mean(var)\n",
    "            tf.summary.scalar('mean', mean)\n",
    "            \n",
    "            with tf.name_scope('stddev'):\n",
    "                stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "            \n",
    "            tf.summary.scalar('stddev', stddev)\n",
    "            tf.summary.scalar('max', tf.reduce_max(var))    \n",
    "            tf.summary.scalar('min', tf.reduce_min(var))\n",
    "            #tf.summary.historgram('histogram', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: to create first convolution layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(input, #previous layer \n",
    "                   num_input_channels,#Num. channels in prev. layer\n",
    "                   filter_size,#width and size of each filter\n",
    "                   num_filters, \n",
    "                   use_pooling=True,): #use 2x2 max pooling\n",
    "    # adding a name scope to ensure logical grouping of layers in graph\n",
    "    with tf.name_scope('Convolutional_Layer'):\n",
    "        \n",
    "        #shape of filter-weights for convolution. Format determined by TensorFlow API\n",
    "        shape = [filter_size,filter_size,num_input_channels,num_filters]\n",
    "    \n",
    "        #Holds the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            #new weights aka filters with the given shape\n",
    "            weights = new_weights(shape=shape)\n",
    "            variable_summaries(weights)\n",
    "        \n",
    "        with tf.name_scope('biases'):\n",
    "            #create new biases one for each filter\n",
    "            biases = new_biases(length=num_filters)\n",
    "            variable_summaries(biases)\n",
    "    \n",
    "        #TensorFlow operation for convolution. Strides are set to 1 in all dimensions. CHECK STRIDE NOTATION\n",
    "        #The first and last stride must be set to 1, \n",
    "        #because the first is for the image number\n",
    "        #second is for the input channel\n",
    "        #e.g. [1,2,2,1] would mean that the filter moves 2 pixels across x and y axes of image\n",
    "        #Padding is set to 'SAME' which means input image is padded with zeros\n",
    "        #making the size of the output the same\n",
    "        layer = tf.nn.conv2d(input=input, \n",
    "                         filter=weights, \n",
    "                        strides=[1,1,1,1],\n",
    "                        padding='SAME')\n",
    "\n",
    "        #biases\n",
    "        layer += biases\n",
    "        \n",
    "        #max pool\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                            ksize=[1,2,2,1],\n",
    "                            strides=[1,2,2,1],\n",
    "                            padding='SAME')\n",
    "    \n",
    "        #Rectified Linear Unit\n",
    "        #Calculates max(x, 0) for each input pixel, x. Adds non-linearity\n",
    "        #Normally ReLU executed before pooling, but since relu(max_pool(x)) == max_pool(relu(x)) \n",
    "        # we save 75% of ReLU operations by max-pooling first.\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "        #dropout\n",
    "        #layer = tf.nn.dropout(layer, 0.3)\n",
    "    \n",
    "        #We use return becauase we will plot the weights later. \n",
    "        return layer, weights\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Flatten a Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    with tf.name_scope('Flatten_Layer'):\n",
    "        #Shape of input layer, assumed to be \n",
    "        #layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "        layer_shape=layer.get_shape()\n",
    "    \n",
    "        #The number of features is: img_height*img_width*num_channels]\n",
    "        num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "        #Reshape layer to just [num_images, num_features]\n",
    "        layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "        return layer_flat, num_features\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Function to create Fully-Connected Layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, #previous layer\n",
    "                num_inputs, #from previous layer\n",
    "                num_outputs,\n",
    "                use_relu = True, #Rectified linear unit\n",
    "                use_dropout = True): \n",
    "    with tf.name_scope('Fully_Connected_Layer'):\n",
    "        #create new weights and biases, call previous function \n",
    "        weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "    \n",
    "        #Calculate the layer as matrix multiplcation of input and weights \n",
    "        #plus the bias values\n",
    "        layer=tf.matmul(input,weights) + biases\n",
    "    \n",
    "        #Use ReLU?\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "      \n",
    "        if use_dropout:\n",
    "            #just added placeholder variable 16May17\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            layer = tf.nn.dropout(layer, keep_prob=0.9)\n",
    "        \n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Placeholder Variables</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tensor for images, multidimensional matrix, None means the tensor holds arbitrary number of images\n",
    "#with each vector of length img_size_flat representing one image.\n",
    "#x = tf.placeholder(tf.float32,shape=[None,img_size_flat],name='x')\n",
    "\n",
    "with tf.name_scope('Input_Images'):\n",
    "    x = tf.placeholder(tf.float32,shape=[None,img_size_flat],name='x')\n",
    "    \n",
    "    x_image = tf.reshape(x,[-1,img_size,img_size,num_channels])\n",
    "\n",
    "    y_true = tf.placeholder(tf.float32,shape=[None,10],name='y_true')\n",
    "\n",
    "    y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convolutional Layer 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Convolutional_Layer/Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convolutional Layer 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 =\\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                  num_input_channels=num_filters1,\n",
    "                  filter_size=filter_size2,\n",
    "                  num_filters=num_filters2,\n",
    "                  use_pooling=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Convolutional_Layer_1/Relu:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Convolutional_Layer_1/weights/Variable:0' shape=(5, 5, 16, 36) dtype=float32_ref>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weights_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Flatten Layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Flatten_Layer/Reshape:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fully Connected Layer 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True,\n",
    "                        use_dropout=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Fully Connected Layer 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1, \n",
    "                           num_inputs=fc_size,\n",
    "                        num_outputs=num_classes,\n",
    "                        use_relu=False,\n",
    "                        use_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Fully_Connected_Layer_1/add:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Predicted Class</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"softmax\"):\n",
    "    #note that here we have only used one fc layer as a predictor\n",
    "    y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"y_pred\"):\n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Cross-function to be optimized</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cost'):\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Optimization Method</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Performance Measures</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Accuracy'):\n",
    "    #vector of booleans whether the predicted class equals the true class of the image\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    #type-cast the booleans to floats (False is 0 and True is 1), then take an average\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create cost and accuracy summaries Merge Tensorboard Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code doesn't work with AWS yet\n",
    "#tf.summary.scalar(\"cost\", cost)\n",
    "#tf.summary.scalar(\"accuracy\", accuracy)\n",
    "#summary_op = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Run Dropout is 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#op to write logs to Tensorboard\n",
    "#summary_writer = tf.summary.FileWriter(logs_path,session.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to perform optimization iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy(show_example_errors = False, \n",
    "                       show_confusion_matrix = False):\n",
    "    num_test = len(data.test.images)\n",
    "    \n",
    "    #Array for the predicted class, calculated in batches and filled into this array\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "    \n",
    "    i = 0 \n",
    "    \n",
    "    while i < num_test:\n",
    "        #The ending index for next batch is denoted by j\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        \n",
    "        images = data.test.images[i:j, :]\n",
    "        \n",
    "        labels = data.test.labels[i:j, :]\n",
    "        \n",
    "        feed_dict = {x:images, \n",
    "                    y_true: labels}\n",
    "        \n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        \n",
    "        i = j\n",
    "    \n",
    "    #true class numbers of the test set \n",
    "    cls_true = data.test.cls\n",
    "    \n",
    "    #Boolean array indicating correct/incorrect image classification\n",
    "    correct = (cls_true == cls_pred)\n",
    "    \n",
    "    #Total number of correct images\n",
    "    correct_sum = correct.sum()\n",
    "    \n",
    "    #accuracy is number of correct images over total images in test set\n",
    "    acc = float(correct_sum) / num_test\n",
    "    \n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} /{2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "    \n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counter for total iterations so far\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #update global variable rather than local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, \n",
    "                   total_iterations + num_iterations):\n",
    "    \n",
    "        #Get a batch of training examples\n",
    "        #x_batch now holds a batch of images and \n",
    "        #y_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "    \n",
    "        #Put the batch into a dict with the proper names\n",
    "        #for placeholder variables in the tf graph\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                          y_true: y_true_batch}\n",
    "    \n",
    "        #Run the optimizer using this batch of trianing data.\n",
    "        #Also runs tensors for cost and summary\n",
    "        #Tf assigns the variables in feed_dict_train \n",
    "        #to the placeholder variables and then runs the optimizer\n",
    "        # why does code use _ ??\n",
    "        #removed summary_op b/c doesn't work with AWS yet 27Jun17\n",
    "        _, c =session.run([optimizer,cost],feed_dict=feed_dict_train)\n",
    "        \n",
    "        #write logs at each iteration\n",
    "        #summary_writer.add_summary(summary, total_iterations)\n",
    "        \n",
    "        #print status each 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "           \n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            \n",
    "            #summary_writer.add_summary(summary, total_iterations)\n",
    "            \n",
    "            print(msg.format(i + 1, acc))\n",
    "            print_test_accuracy()\n",
    "        \n",
    "    #Update the total iteration\n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    #total time calculation\n",
    "    end_time = time.time()\n",
    "       \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \"+ str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    cls_true = data.test.cls\n",
    "    \n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                         y_pred=cls_pred)\n",
    "    #print as text\n",
    "    print(cm)\n",
    "    \n",
    "    #plot as image\n",
    "    plt.matshow(cm)\n",
    "    \n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('true')\n",
    "    \n",
    "    #ensure it is plotted in one Notebook cell\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to show performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 9.8% (984 /10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  20.3%\n",
      "Accuracy on Test-Set: 8.9% (891 /10000)\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10,000 optimizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    101, Training Accuracy:  92.2%\n",
      "Accuracy on Test-Set: 91.6% (9157 /10000)\n",
      "Optimization Iteration:    201, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 93.8% (9384 /10000)\n",
      "Optimization Iteration:    301, Training Accuracy:  95.3%\n",
      "Accuracy on Test-Set: 96.2% (9619 /10000)\n",
      "Optimization Iteration:    401, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 96.6% (9658 /10000)\n",
      "Optimization Iteration:    501, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 97.3% (9726 /10000)\n",
      "Optimization Iteration:    601, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 96.9% (9687 /10000)\n",
      "Optimization Iteration:    701, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 97.7% (9774 /10000)\n",
      "Optimization Iteration:    801, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.0% (9795 /10000)\n",
      "Optimization Iteration:    901, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 97.9% (9791 /10000)\n",
      "Optimization Iteration:   1001, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 97.8% (9776 /10000)\n",
      "Optimization Iteration:   1101, Training Accuracy:  93.8%\n",
      "Accuracy on Test-Set: 98.0% (9805 /10000)\n",
      "Optimization Iteration:   1201, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.6% (9856 /10000)\n",
      "Optimization Iteration:   1301, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.2% (9815 /10000)\n",
      "Optimization Iteration:   1401, Training Accuracy:  93.8%\n",
      "Accuracy on Test-Set: 98.3% (9827 /10000)\n",
      "Optimization Iteration:   1501, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.6% (9859 /10000)\n",
      "Optimization Iteration:   1601, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.5% (9847 /10000)\n",
      "Optimization Iteration:   1701, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.6% (9860 /10000)\n",
      "Optimization Iteration:   1801, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.6% (9860 /10000)\n",
      "Optimization Iteration:   1901, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.8% (9879 /10000)\n",
      "Optimization Iteration:   2001, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.6% (9857 /10000)\n",
      "Optimization Iteration:   2101, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.8% (9882 /10000)\n",
      "Optimization Iteration:   2201, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 98.6% (9857 /10000)\n",
      "Optimization Iteration:   2301, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.7% (9869 /10000)\n",
      "Optimization Iteration:   2401, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 98.6% (9863 /10000)\n",
      "Optimization Iteration:   2501, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.9% (9889 /10000)\n",
      "Optimization Iteration:   2601, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.9% (9892 /10000)\n",
      "Optimization Iteration:   2701, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.8% (9877 /10000)\n",
      "Optimization Iteration:   2801, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.9% (9893 /10000)\n",
      "Optimization Iteration:   2901, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 99.0% (9897 /10000)\n",
      "Optimization Iteration:   3001, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9904 /10000)\n",
      "Optimization Iteration:   3101, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.8% (9881 /10000)\n",
      "Optimization Iteration:   3201, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9905 /10000)\n",
      "Optimization Iteration:   3301, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.9% (9885 /10000)\n",
      "Optimization Iteration:   3401, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9908 /10000)\n",
      "Optimization Iteration:   3501, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.2% (9915 /10000)\n",
      "Optimization Iteration:   3601, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9906 /10000)\n",
      "Optimization Iteration:   3701, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9899 /10000)\n",
      "Optimization Iteration:   3801, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.9% (9887 /10000)\n",
      "Optimization Iteration:   3901, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9907 /10000)\n",
      "Optimization Iteration:   4001, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.1% (9909 /10000)\n",
      "Optimization Iteration:   4101, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9898 /10000)\n",
      "Optimization Iteration:   4201, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.9% (9889 /10000)\n",
      "Optimization Iteration:   4301, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.9% (9894 /10000)\n",
      "Optimization Iteration:   4401, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9900 /10000)\n",
      "Optimization Iteration:   4501, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9900 /10000)\n",
      "Optimization Iteration:   4601, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.9% (9889 /10000)\n",
      "Optimization Iteration:   4701, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.2% (9920 /10000)\n",
      "Optimization Iteration:   4801, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9905 /10000)\n",
      "Optimization Iteration:   4901, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9912 /10000)\n",
      "Optimization Iteration:   5001, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.0% (9899 /10000)\n",
      "Optimization Iteration:   5101, Training Accuracy:  96.9%\n",
      "Accuracy on Test-Set: 99.1% (9912 /10000)\n",
      "Optimization Iteration:   5201, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.1% (9911 /10000)\n",
      "Optimization Iteration:   5301, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9912 /10000)\n",
      "Optimization Iteration:   5401, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9900 /10000)\n",
      "Optimization Iteration:   5501, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.8% (9882 /10000)\n",
      "Optimization Iteration:   5601, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.2% (9915 /10000)\n",
      "Optimization Iteration:   5701, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9901 /10000)\n",
      "Optimization Iteration:   5801, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.1% (9906 /10000)\n",
      "Optimization Iteration:   5901, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9896 /10000)\n",
      "Optimization Iteration:   6001, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9912 /10000)\n",
      "Optimization Iteration:   6101, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9914 /10000)\n",
      "Optimization Iteration:   6201, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.9% (9890 /10000)\n",
      "Optimization Iteration:   6301, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9899 /10000)\n",
      "Optimization Iteration:   6401, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.9% (9891 /10000)\n",
      "Optimization Iteration:   6501, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.1% (9907 /10000)\n",
      "Optimization Iteration:   6601, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9908 /10000)\n",
      "Optimization Iteration:   6701, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9907 /10000)\n",
      "Optimization Iteration:   6801, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9914 /10000)\n",
      "Optimization Iteration:   6901, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9901 /10000)\n",
      "Optimization Iteration:   7001, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.1% (9905 /10000)\n",
      "Optimization Iteration:   7101, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.8% (9884 /10000)\n",
      "Optimization Iteration:   7201, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9910 /10000)\n",
      "Optimization Iteration:   7301, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9905 /10000)\n",
      "Optimization Iteration:   7401, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.2% (9919 /10000)\n",
      "Optimization Iteration:   7501, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.1% (9906 /10000)\n",
      "Optimization Iteration:   7601, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.1% (9914 /10000)\n",
      "Optimization Iteration:   7701, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9905 /10000)\n",
      "Optimization Iteration:   7801, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9897 /10000)\n",
      "Optimization Iteration:   7901, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9896 /10000)\n",
      "Optimization Iteration:   8001, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 98.9% (9892 /10000)\n",
      "Optimization Iteration:   8101, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 99.0% (9895 /10000)\n",
      "Optimization Iteration:   8201, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9901 /10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   8301, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.2% (9918 /10000)\n",
      "Optimization Iteration:   8401, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9899 /10000)\n",
      "Optimization Iteration:   8501, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9910 /10000)\n",
      "Optimization Iteration:   8601, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9913 /10000)\n",
      "Optimization Iteration:   8701, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9912 /10000)\n",
      "Optimization Iteration:   8801, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9903 /10000)\n",
      "Optimization Iteration:   8901, Training Accuracy:  98.4%\n",
      "Accuracy on Test-Set: 98.9% (9890 /10000)\n",
      "Optimization Iteration:   9001, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9904 /10000)\n",
      "Optimization Iteration:   9101, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9903 /10000)\n",
      "Optimization Iteration:   9201, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.2% (9919 /10000)\n",
      "Optimization Iteration:   9301, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9910 /10000)\n",
      "Optimization Iteration:   9401, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9899 /10000)\n",
      "Optimization Iteration:   9501, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.2% (9920 /10000)\n",
      "Optimization Iteration:   9601, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9907 /10000)\n",
      "Optimization Iteration:   9701, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.0% (9904 /10000)\n",
      "Optimization Iteration:   9801, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9911 /10000)\n",
      "Optimization Iteration:   9901, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.1% (9908 /10000)\n",
      "Optimization Iteration:  10001, Training Accuracy: 100.0%\n",
      "Accuracy on Test-Set: 99.2% (9915 /10000)\n",
      "Time usage: 0:01:21\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations =10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 99.2% (9916 /10000)\n",
      "Confusion Matrix:\n",
      "[[ 979    0    0    0    0    0    0    1    0    0]\n",
      " [   0 1133    0    1    0    0    0    0    1    0]\n",
      " [   1    0 1026    0    1    0    0    3    1    0]\n",
      " [   0    0    2 1001    0    5    0    1    0    1]\n",
      " [   0    1    0    0  972    0    1    0    1    7]\n",
      " [   0    0    0    4    0  887    0    0    0    1]\n",
      " [   9    3    0    0    2    6  938    0    0    0]\n",
      " [   0    2    5    0    0    0    0 1020    1    0]\n",
      " [   3    0    1    0    1    3    1    0  962    3]\n",
      " [   0    0    0    0    5    2    0    2    2  998]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARIAAAD3CAYAAADRydumAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAq/zqwIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f1104d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_test_accuracy(show_confusion_matrix = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
